{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.3333333333333333,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 633349634785280.0,
      "learning_rate": 0.02984,
      "loss": 10.7808,
      "step": 10
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 48317362864128.0,
      "learning_rate": 0.029679999999999998,
      "loss": 10.8821,
      "step": 20
    },
    {
      "epoch": 0.08,
      "grad_norm": 288997736448.0,
      "learning_rate": 0.029519999999999998,
      "loss": 11.427,
      "step": 30
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 5937992704.0,
      "learning_rate": 0.02936,
      "loss": 11.0117,
      "step": 40
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 76267688.0,
      "learning_rate": 0.0292,
      "loss": 11.3711,
      "step": 50
    },
    {
      "epoch": 0.16,
      "grad_norm": 929786.375,
      "learning_rate": 0.029039999999999996,
      "loss": 11.4416,
      "step": 60
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 68856.15625,
      "learning_rate": 0.02888,
      "loss": 11.346,
      "step": 70
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 22033718.0,
      "learning_rate": 0.02872,
      "loss": 11.509,
      "step": 80
    },
    {
      "epoch": 0.24,
      "grad_norm": 981306880.0,
      "learning_rate": 0.02856,
      "loss": 11.1681,
      "step": 90
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 4715242.5,
      "learning_rate": 0.028399999999999998,
      "loss": 11.1441,
      "step": 100
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 91649640.0,
      "learning_rate": 0.02824,
      "loss": 11.122,
      "step": 110
    },
    {
      "epoch": 0.32,
      "grad_norm": 14654689.0,
      "learning_rate": 0.02808,
      "loss": 10.8535,
      "step": 120
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 1125069.375,
      "learning_rate": 0.027919999999999997,
      "loss": 10.781,
      "step": 130
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 40328359936.0,
      "learning_rate": 0.02776,
      "loss": 10.744,
      "step": 140
    },
    {
      "epoch": 0.4,
      "grad_norm": 187384320.0,
      "learning_rate": 0.0276,
      "loss": 10.7965,
      "step": 150
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 365854976.0,
      "learning_rate": 0.02744,
      "loss": 11.0017,
      "step": 160
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 35474563072.0,
      "learning_rate": 0.02728,
      "loss": 10.961,
      "step": 170
    },
    {
      "epoch": 0.48,
      "grad_norm": 47592374272.0,
      "learning_rate": 0.02712,
      "loss": 11.0436,
      "step": 180
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 36738560.0,
      "learning_rate": 0.026959999999999998,
      "loss": 11.0349,
      "step": 190
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 174079008.0,
      "learning_rate": 0.026799999999999997,
      "loss": 10.7468,
      "step": 200
    },
    {
      "epoch": 0.56,
      "grad_norm": 79624298496.0,
      "learning_rate": 0.02664,
      "loss": 10.8919,
      "step": 210
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 111466528768.0,
      "learning_rate": 0.02648,
      "loss": 10.8127,
      "step": 220
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 20533790.0,
      "learning_rate": 0.02632,
      "loss": 10.6471,
      "step": 230
    },
    {
      "epoch": 0.64,
      "grad_norm": 324150788096.0,
      "learning_rate": 0.02616,
      "loss": 10.9127,
      "step": 240
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 483697472.0,
      "learning_rate": 0.026,
      "loss": 10.8032,
      "step": 250
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 71179326980096.0,
      "learning_rate": 0.02584,
      "loss": 10.9459,
      "step": 260
    },
    {
      "epoch": 0.72,
      "grad_norm": 22718148608.0,
      "learning_rate": 0.025679999999999998,
      "loss": 11.1146,
      "step": 270
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 75955716489216.0,
      "learning_rate": 0.02552,
      "loss": 11.04,
      "step": 280
    },
    {
      "epoch": 0.7733333333333333,
      "grad_norm": 987788187009024.0,
      "learning_rate": 0.02536,
      "loss": 11.1937,
      "step": 290
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.459956746688922e+16,
      "learning_rate": 0.025199999999999997,
      "loss": 10.924,
      "step": 300
    },
    {
      "epoch": 0.8266666666666667,
      "grad_norm": 19753312256.0,
      "learning_rate": 0.02504,
      "loss": 11.2908,
      "step": 310
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 38990782464.0,
      "learning_rate": 0.02488,
      "loss": 11.1886,
      "step": 320
    },
    {
      "epoch": 0.88,
      "grad_norm": 6.621092034138604e+17,
      "learning_rate": 0.02472,
      "loss": 11.2203,
      "step": 330
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 3366637763821568.0,
      "learning_rate": 0.02456,
      "loss": 11.326,
      "step": 340
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": Infinity,
      "learning_rate": 0.024399999999999998,
      "loss": 10.8874,
      "step": 350
    },
    {
      "epoch": 0.96,
      "grad_norm": 2554666680320.0,
      "learning_rate": 0.02424,
      "loss": 11.3108,
      "step": 360
    },
    {
      "epoch": 0.9866666666666667,
      "grad_norm": 9.660689695742362e+16,
      "learning_rate": 0.024079999999999997,
      "loss": 12.2057,
      "step": 370
    },
    {
      "epoch": 1.0133333333333334,
      "grad_norm": 6115785395142656.0,
      "learning_rate": 0.02392,
      "loss": 12.565,
      "step": 380
    },
    {
      "epoch": 1.04,
      "grad_norm": 3782626821275648.0,
      "learning_rate": 0.02376,
      "loss": 12.8845,
      "step": 390
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 3.1699742715019264e+16,
      "learning_rate": 0.0236,
      "loss": 12.9692,
      "step": 400
    },
    {
      "epoch": 1.0933333333333333,
      "grad_norm": 51431403520.0,
      "learning_rate": 0.02344,
      "loss": 13.3995,
      "step": 410
    },
    {
      "epoch": 1.12,
      "grad_norm": 931101.625,
      "learning_rate": 0.02328,
      "loss": 12.3165,
      "step": 420
    },
    {
      "epoch": 1.1466666666666667,
      "grad_norm": 96826304.0,
      "learning_rate": 0.02312,
      "loss": 11.9756,
      "step": 430
    },
    {
      "epoch": 1.1733333333333333,
      "grad_norm": 108111760.0,
      "learning_rate": 0.022959999999999998,
      "loss": 11.8607,
      "step": 440
    },
    {
      "epoch": 1.2,
      "grad_norm": 50807684.0,
      "learning_rate": 0.0228,
      "loss": 11.7493,
      "step": 450
    },
    {
      "epoch": 1.2266666666666666,
      "grad_norm": 7298126.0,
      "learning_rate": 0.02264,
      "loss": 11.521,
      "step": 460
    },
    {
      "epoch": 1.2533333333333334,
      "grad_norm": 6528302.0,
      "learning_rate": 0.022479999999999997,
      "loss": 11.9693,
      "step": 470
    },
    {
      "epoch": 1.28,
      "grad_norm": 99408072.0,
      "learning_rate": 0.02232,
      "loss": 12.1214,
      "step": 480
    },
    {
      "epoch": 1.3066666666666666,
      "grad_norm": 269268768.0,
      "learning_rate": 0.02216,
      "loss": 11.6435,
      "step": 490
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 15523381.0,
      "learning_rate": 0.022,
      "loss": 12.0724,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 1875,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5040407808344064.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
